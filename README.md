# リアルタイム自動運転システム

画面から運転環境をリアルタイムで解析し、適切な運転指示を生成するAIシステム。

## 機能概要

- **リアルタイム画面キャプチャ**: スクリーンから動画入力を取得
- **車線検出**: Cannyエッジ検出とハフ変換による車線認識
- **物体検出**: YOLOv8による車両、歩行者、障害物検出
- **意思決定**: 検出結果に基づく運転指示生成（加速、ブレーキ、操舵）
- **距離推定**: 物体サイズに基づく簡易距離計算
- **リアルタイム可視化**: 検出結果と運転指示の即時表示

## システム要件

- Python 3.8+
- OpenCV 4.8+
- PyTorch 2.0+
- CUDA対応GPU（推奨）

## インストール方法

```bash
# 依存パッケージをインストール
pip install -r requirements.txt

# YOLOv8モデルが自動ダウンロードされます
```

## 使用方法

```bash
python autonomous_driver.py
```

### 操作方法

- **ESCキー**: システム停止
- **ウィンドウを閉じる**: システム停止

## 検出対象

### 車線
- 左右車線の検出と追跡
- 車線逸脱警告

### 物体
- 車両（car, truck, bus）
- 二輪車（motorcycle, bicycle）
- 歩行者（person）

## 運転指示

### アクション種別
- `accelerate`: 加速
- `brake`: ブレーキ
- `turn_left`: 左折
- `turn_right`: 右折
- `straight`: 直進

### 緊急度レベル
- **10**: 緊急事態（即時ブレーキ）
- **8**: 高い緊急度
- **5**: 中程度の緊急度
- **2**: 低い緊急度

## 設定ファイル

`config.py`でシステムパラメータを調整：

- スクリーンキャプチャ領域
- 検出閾値
- 安全距離設定
- 可視化オプション

## アルゴリズム詳細

### 車線検出
1. グレースケール変換
2. ガウシアンブラーによるノイズ除去
3. Cannyエッジ検出
4. 関心領域（ROI）マスク適用
5. ハフ変換による線分検出
6. 左右車線への分類と平均化

### 物体検出
1. YOLOv8による物体検出
2. 信頼度フィルタリング
3. ターゲットクラス抽出
4. バウンディングボックスサイズに基づく距離推定

### 意思決定
1. 緊急事態チェック（衝突危険）
2. 車線位置解析（逸脱検出）
3. 前方障害物チェック（車間距離）
4. 緊急度に基づく指示選択

## 性能

- **目標FPS**: 30fps
- **検出距離**: 1-100m
- **応答時間**: <100ms

## 注意事項

- 本システムは研究・実験用です
- 実際の車両運転には使用しないでください
- スクリーンキャプチャ領域を適切に設定してください
- 十分な光量のある環境で使用してください

## トラブルシューティング

### YOLOモデルがダウンロードされない
```bash
# 手動でモデルをダウンロード
wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt
```

### FPSが低い場合
- GPUドライバを最新版に更新
- キャプチャ解像度を下げる
- `config.py`でパラメータ調整

### 車線が検出されない
- 明るさを調整
- `LANE_DETECTION`の閾値を調整
- キャプチャ領域を道路に合わせる

## ライセンス

MIT License

## 貢献

バグ報告や機能改善のプルリクエストを歓迎します。
